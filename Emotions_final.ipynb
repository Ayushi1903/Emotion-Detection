{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f1b6052",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, BatchNormalization, Dense, Flatten, Activation\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pydot_ng\n",
    "import graphviz\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d24e2e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 7\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "Img_height = 48\n",
    "Img_width = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9f3518b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels     Usage\n",
       "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
       "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
       "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
       "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
       "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Desktop\\emotion.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5245fe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels = data['pixels'].tolist() \n",
    "faces = []\n",
    "\n",
    "for pixel_sequence in pixels:\n",
    "    face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
    "    face = np.asarray(face).reshape(Img_height, Img_width) \n",
    "    faces.append(face.astype('float32'))\n",
    "\n",
    "faces = np.asarray(faces)\n",
    "faces = np.expand_dims(faces, -1)\n",
    "\n",
    "emotions = pd.get_dummies(data['emotion']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd7d0967",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(faces, emotions, test_size=0.1, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=41)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e4da96",
   "metadata": {},
   "source": [
    "Emotions Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9793faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Block-1: The First Convolutional Block\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), padding='same', \n",
    "                 kernel_initializer='he_normal',\n",
    "                 activation=\"relu\", \n",
    "                 input_shape=(Img_height, Img_width, 1), \n",
    "                 name=\"Conv1\"))\n",
    "\n",
    "model.add(BatchNormalization(name=\"Batch_Norm1\"))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), padding='same', \n",
    "                 kernel_initializer='he_normal', \n",
    "                 activation=\"relu\", name=\"Conv2\"))\n",
    "\n",
    "model.add(BatchNormalization(name=\"Batch_Norm2\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), name=\"Maxpool1\"))\n",
    "model.add(Dropout(0.5, name=\"Dropout1\"))\n",
    "\n",
    "# Block-2: The Second Convolutional Block\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', \n",
    "                 kernel_initializer='he_normal',\n",
    "                 activation=\"relu\", name=\"Conv3\"))\n",
    "\n",
    "model.add(BatchNormalization(name=\"Batch_Norm3\"))\n",
    "\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),padding='same',\n",
    "                 kernel_initializer='he_normal', \n",
    "                 activation=\"relu\", name=\"Conv4\"))\n",
    "\n",
    "model.add(BatchNormalization(name=\"Batch_Norm4\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), name=\"Maxpool2\"))\n",
    "model.add(Dropout(0.5, name=\"Dropout2\"))\n",
    "\n",
    "# Block-3: The Third Convolutional Block\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding='same', \n",
    "                 kernel_initializer='he_normal', \n",
    "                 activation=\"relu\", name=\"Conv5\"))\n",
    "\n",
    "model.add(BatchNormalization(name=\"Batch_Norm5\"))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding='same', \n",
    "                 kernel_initializer='he_normal',\n",
    "                 activation=\"relu\", name=\"Conv6\"))\n",
    "\n",
    "model.add(BatchNormalization(name=\"Batch_Norm6\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), name=\"Maxpool3\"))\n",
    "model.add(Dropout(0.5, name=\"Dropout3\"))\n",
    "\n",
    "# Block-4: The Fully Connected Block\n",
    "\n",
    "model.add(Flatten(name=\"Flatten\"))\n",
    "model.add(Dense(64, activation=\"relu\", kernel_initializer='he_normal', name=\"Dense\"))\n",
    "model.add(BatchNormalization(name=\"Batch_Norm7\"))\n",
    "model.add(Dropout(0.5, name=\"Dropout4\"))\n",
    "\n",
    "# Block-5: The Output Block\n",
    "\n",
    "model.add(Dense(num_classes, activation=\"softmax\", kernel_initializer='he_normal', name = \"Output\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3eda05ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Conv1 (Conv2D)              (None, 48, 48, 32)        320       \n",
      "                                                                 \n",
      " Batch_Norm1 (BatchNormaliza  (None, 48, 48, 32)       128       \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " Conv2 (Conv2D)              (None, 48, 48, 32)        9248      \n",
      "                                                                 \n",
      " Batch_Norm2 (BatchNormaliza  (None, 48, 48, 32)       128       \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " Maxpool1 (MaxPooling2D)     (None, 24, 24, 32)        0         \n",
      "                                                                 \n",
      " Dropout1 (Dropout)          (None, 24, 24, 32)        0         \n",
      "                                                                 \n",
      " Conv3 (Conv2D)              (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " Batch_Norm3 (BatchNormaliza  (None, 24, 24, 64)       256       \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " Conv4 (Conv2D)              (None, 24, 24, 64)        36928     \n",
      "                                                                 \n",
      " Batch_Norm4 (BatchNormaliza  (None, 24, 24, 64)       256       \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " Maxpool2 (MaxPooling2D)     (None, 12, 12, 64)        0         \n",
      "                                                                 \n",
      " Dropout2 (Dropout)          (None, 12, 12, 64)        0         \n",
      "                                                                 \n",
      " Conv5 (Conv2D)              (None, 12, 12, 128)       73856     \n",
      "                                                                 \n",
      " Batch_Norm5 (BatchNormaliza  (None, 12, 12, 128)      512       \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " Conv6 (Conv2D)              (None, 12, 12, 128)       147584    \n",
      "                                                                 \n",
      " Batch_Norm6 (BatchNormaliza  (None, 12, 12, 128)      512       \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " Maxpool3 (MaxPooling2D)     (None, 6, 6, 128)         0         \n",
      "                                                                 \n",
      " Dropout3 (Dropout)          (None, 6, 6, 128)         0         \n",
      "                                                                 \n",
      " Flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " Dense (Dense)               (None, 64)                294976    \n",
      "                                                                 \n",
      " Batch_Norm7 (BatchNormaliza  (None, 64)               256       \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " Dropout4 (Dropout)          (None, 64)                0         \n",
      "                                                                 \n",
      " Output (Dense)              (None, 7)                 455       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 583,911\n",
      "Trainable params: 582,887\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93800ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayush\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-7),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86d8348f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='logs3')\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_accuracy', factor=0.9, patience=3, verbose=1)\n",
    "early_stopper = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=8, verbose=1, mode='auto')\n",
    "checkpointer = ModelCheckpoint(\"emotions3.h5\", monitor='val_accuracy', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61158ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "455/455 [==============================] - ETA: 0s - loss: 2.0569 - accuracy: 0.2566\n",
      "Epoch 1: val_accuracy improved from -inf to 0.37113, saving model to emotions3.h5\n",
      "455/455 [==============================] - 336s 734ms/step - loss: 2.0569 - accuracy: 0.2566 - val_loss: 1.6223 - val_accuracy: 0.3711 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "455/455 [==============================] - ETA: 0s - loss: 1.6320 - accuracy: 0.3779\n",
      "Epoch 2: val_accuracy improved from 0.37113 to 0.43410, saving model to emotions3.h5\n",
      "455/455 [==============================] - 340s 747ms/step - loss: 1.6320 - accuracy: 0.3779 - val_loss: 1.4626 - val_accuracy: 0.4341 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "455/455 [==============================] - ETA: 0s - loss: 1.4934 - accuracy: 0.4232\n",
      "Epoch 3: val_accuracy improved from 0.43410 to 0.47896, saving model to emotions3.h5\n",
      "455/455 [==============================] - 436s 960ms/step - loss: 1.4934 - accuracy: 0.4232 - val_loss: 1.3372 - val_accuracy: 0.4790 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "455/455 [==============================] - ETA: 0s - loss: 1.3934 - accuracy: 0.4668\n",
      "Epoch 4: val_accuracy improved from 0.47896 to 0.49791, saving model to emotions3.h5\n",
      "455/455 [==============================] - 517s 1s/step - loss: 1.3934 - accuracy: 0.4668 - val_loss: 1.3190 - val_accuracy: 0.4979 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "455/455 [==============================] - ETA: 0s - loss: 1.3265 - accuracy: 0.4937\n",
      "Epoch 5: val_accuracy did not improve from 0.49791\n",
      "455/455 [==============================] - 530s 1s/step - loss: 1.3265 - accuracy: 0.4937 - val_loss: 1.3309 - val_accuracy: 0.4907 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "455/455 [==============================] - ETA: 0s - loss: 1.2879 - accuracy: 0.5121\n",
      "Epoch 6: val_accuracy improved from 0.49791 to 0.53246, saving model to emotions3.h5\n",
      "455/455 [==============================] - 733s 2s/step - loss: 1.2879 - accuracy: 0.5121 - val_loss: 1.2132 - val_accuracy: 0.5325 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "455/455 [==============================] - ETA: 0s - loss: 1.2525 - accuracy: 0.5225 \n",
      "Epoch 7: val_accuracy improved from 0.53246 to 0.55280, saving model to emotions3.h5\n",
      "455/455 [==============================] - 5365s 12s/step - loss: 1.2525 - accuracy: 0.5225 - val_loss: 1.1657 - val_accuracy: 0.5528 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "455/455 [==============================] - ETA: 0s - loss: 1.2202 - accuracy: 0.5367\n",
      "Epoch 8: val_accuracy improved from 0.55280 to 0.56339, saving model to emotions3.h5\n",
      "455/455 [==============================] - 420s 923ms/step - loss: 1.2202 - accuracy: 0.5367 - val_loss: 1.1477 - val_accuracy: 0.5634 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "126/455 [=======>......................] - ETA: 6:23 - loss: 1.2201 - accuracy: 0.5392"
     ]
    }
   ],
   "source": [
    "model.fit(np.array(X_train), np.array(y_train),\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(np.array(X_test), np.array(y_test)),\n",
    "          shuffle=True,\n",
    "          callbacks=[lr_reducer, tensorboard, early_stopper, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90530cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
